{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold,cross_val_predict,cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import neighbors\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: (1460, 81)\n",
      "\n",
      "Data columns: ['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType', 'SaleCondition', 'SalePrice']\n",
      "\n",
      "Datatype:\n",
      " Id                 int64\n",
      "MSSubClass         int64\n",
      "MSZoning          object\n",
      "LotFrontage      float64\n",
      "LotArea            int64\n",
      "Street            object\n",
      "Alley             object\n",
      "LotShape          object\n",
      "LandContour       object\n",
      "Utilities         object\n",
      "LotConfig         object\n",
      "LandSlope         object\n",
      "Neighborhood      object\n",
      "Condition1        object\n",
      "Condition2        object\n",
      "BldgType          object\n",
      "HouseStyle        object\n",
      "OverallQual        int64\n",
      "OverallCond        int64\n",
      "YearBuilt          int64\n",
      "YearRemodAdd       int64\n",
      "RoofStyle         object\n",
      "RoofMatl          object\n",
      "Exterior1st       object\n",
      "Exterior2nd       object\n",
      "MasVnrType        object\n",
      "MasVnrArea       float64\n",
      "ExterQual         object\n",
      "ExterCond         object\n",
      "Foundation        object\n",
      "                  ...   \n",
      "BedroomAbvGr       int64\n",
      "KitchenAbvGr       int64\n",
      "KitchenQual       object\n",
      "TotRmsAbvGrd       int64\n",
      "Functional        object\n",
      "Fireplaces         int64\n",
      "FireplaceQu       object\n",
      "GarageType        object\n",
      "GarageYrBlt      float64\n",
      "GarageFinish      object\n",
      "GarageCars         int64\n",
      "GarageArea         int64\n",
      "GarageQual        object\n",
      "GarageCond        object\n",
      "PavedDrive        object\n",
      "WoodDeckSF         int64\n",
      "OpenPorchSF        int64\n",
      "EnclosedPorch      int64\n",
      "3SsnPorch          int64\n",
      "ScreenPorch        int64\n",
      "PoolArea           int64\n",
      "PoolQC            object\n",
      "Fence             object\n",
      "MiscFeature       object\n",
      "MiscVal            int64\n",
      "MoSold             int64\n",
      "YrSold             int64\n",
      "SaleType          object\n",
      "SaleCondition     object\n",
      "SalePrice          int64\n",
      "Length: 81, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('C:/Users/Nandhini Giridharan/Downloads/train.csv')\n",
    "df.head()\n",
    "print(\"Dataset size:\",df.shape)\n",
    "print(\"\\nData columns:\", list(df.columns))\n",
    "print(\"\\nDatatype:\\n\",df.dtypes)\n",
    "x=  df.select_dtypes([np.number]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df['SalePrice']\n",
    "X=df.drop(['SalePrice'],axis=1)\n",
    "X=X.select_dtypes(np.number)\n",
    "\n",
    "#Missing value imputation\n",
    "for col in X.columns:\n",
    "    X[col].fillna(X[col].median(axis=0),inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id  :  -0.021916719443431106  , -0.01854562453597749\n",
      "MSSubClass  :  -0.08428413512659517  , 0.007192252911733475\n",
      "LotFrontage  :  0.33477085313975996  , 0.37558979220878164\n",
      "LotArea  :  0.2638433538714056  , 0.45646058339121154\n",
      "OverallQual  :  0.7909816005838051  , 0.8098285862017292\n",
      "OverallCond  :  -0.077855894048678  , -0.12932494660061317\n",
      "YearBuilt  :  0.5228973328794969  , 0.6526815462850586\n",
      "YearRemodAdd  :  0.5071009671113862  , 0.5711589780582342\n",
      "MasVnrArea  :  0.4726144990045737  , 0.41590612670677174\n",
      "BsmtFinSF1  :  0.3864198062421533  , 0.3018712035800953\n",
      "BsmtFinSF2  :  -0.01137812145021514  , -0.038806132045894184\n",
      "BsmtUnfSF  :  0.2144791055469689  , 0.18519662942076204\n",
      "TotalBsmtSF  :  0.6135805515591953  , 0.6027254448924096\n",
      "1stFlrSF  :  0.6058521846919146  , 0.5754078354212824\n",
      "2ndFlrSF  :  0.3193338028320678  , 0.29359798822238187\n",
      "LowQualFinSF  :  -0.025606130000679534  , -0.06771915407896568\n",
      "GrLivArea  :  0.708624477612652  , 0.7313095834659141\n",
      "BsmtFullBath  :  0.22712223313149424  , 0.22512486719612365\n",
      "BsmtHalfBath  :  -0.016844154297359016  , -0.012188876310787317\n",
      "FullBath  :  0.560663762748446  , 0.6359570562496957\n",
      "HalfBath  :  0.2841076755947825  , 0.34300754918568294\n",
      "BedroomAbvGr  :  0.16821315430073996  , 0.2349067178902786\n",
      "KitchenAbvGr  :  -0.13590737084214122  , -0.1648257549850205\n",
      "TotRmsAbvGrd  :  0.5337231555820281  , 0.5325859351169929\n",
      "Fireplaces  :  0.4669288367515278  , 0.5192474498367013\n",
      "GarageYrBlt  :  0.4667536523633395  , 0.5632564188677867\n",
      "GarageCars  :  0.640409197258352  , 0.6907109670497434\n",
      "GarageArea  :  0.6234314389183616  , 0.6493785338868229\n",
      "WoodDeckSF  :  0.3244134445681299  , 0.3538016079587888\n",
      "OpenPorchSF  :  0.3158562271160552  , 0.4775606622825264\n",
      "EnclosedPorch  :  -0.12857795792595675  , -0.21839362055219821\n",
      "3SsnPorch  :  0.0445836653357484  , 0.06544021620062833\n",
      "ScreenPorch  :  0.11144657114291123  , 0.1000697202012266\n",
      "PoolArea  :  0.09240354949187321  , 0.05845299668989175\n",
      "MiscVal  :  -0.021189579640303255  , -0.0627270024962966\n",
      "MoSold  :  0.04643224522381935  , 0.06943224370457042\n",
      "YrSold  :  -0.028922585168730326  , -0.02989913491261529\n",
      "['LotFrontage', 'LotArea', 'OverallQual', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'BsmtFullBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch']\n",
      "24   0\n"
     ]
    }
   ],
   "source": [
    "plt.scatter(df['1stFlrSF'],df['SalePrice'])\n",
    "plt.show()\n",
    "s=0\n",
    "r=0\n",
    "useful_col=[]\n",
    "for col in X.columns:\n",
    "    corr, _ = pearsonr(Y,X[col])\n",
    "    corr1,_= spearmanr(Y,X[col])\n",
    "    if (abs(corr1) > abs(corr)): s+=1\n",
    "    print(col,\" : \",corr,\" ,\", corr1)\n",
    "    if abs(corr1)>.2:\n",
    "        useful_col.append(col)\n",
    "print(useful_col)\n",
    "print(s,\" \",r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error 24647.42217425877\n",
      "R squared 0.8782753468261183\n",
      "Root mean squared error 27998.093940391747\n",
      "R squared 0.8429302796268192\n",
      "     Column names    importance\n",
      "14       2ndFlrSF -7.558249e+16\n",
      "13       1stFlrSF -6.693554e+16\n",
      "12    TotalBsmtSF -4.623019e+16\n",
      "15   LowQualFinSF -8.418819e+15\n",
      "21   BedroomAbvGr -8.250780e+03\n",
      "1      MSSubClass -8.105740e+03\n",
      "22   KitchenAbvGr -2.622470e+03\n",
      "2     LotFrontage -1.720060e+03\n",
      "27     GarageArea -1.528130e+03\n",
      "36         YrSold -1.200000e+03\n",
      "29    OpenPorchSF -7.004600e+02\n",
      "20       HalfBath -5.628700e+02\n",
      "0              Id -4.463500e+02\n",
      "33       PoolArea -3.327500e+02\n",
      "34        MiscVal -2.586700e+02\n",
      "35         MoSold -2.199500e+02\n",
      "31      3SsnPorch  9.111000e+01\n",
      "30  EnclosedPorch  1.028950e+03\n",
      "18   BsmtHalfBath  1.200280e+03\n",
      "7    YearRemodAdd  1.979830e+03\n",
      "19       FullBath  2.713940e+03\n",
      "28     WoodDeckSF  2.915110e+03\n",
      "32    ScreenPorch  3.143590e+03\n",
      "24     Fireplaces  3.159830e+03\n",
      "25    GarageYrBlt  3.500400e+03\n",
      "3         LotArea  3.745410e+03\n",
      "5     OverallCond  5.314860e+03\n",
      "8      MasVnrArea  5.511690e+03\n",
      "17   BsmtFullBath  5.866230e+03\n",
      "6       YearBuilt  8.015700e+03\n",
      "26     GarageCars  9.783310e+03\n",
      "23   TotRmsAbvGrd  9.848430e+03\n",
      "4     OverallQual  2.549190e+04\n",
      "10     BsmtFinSF2  1.699961e+16\n",
      "11      BsmtUnfSF  4.656336e+16\n",
      "9      BsmtFinSF1  4.806302e+16\n",
      "16      GrLivArea  9.098403e+16\n",
      "[12:02:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error 23619.51234596703\n",
      "R squared 0.8882165803030841\n"
     ]
    }
   ],
   "source": [
    "#Train test split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=.2)\n",
    "scalar=preprocessing.StandardScaler().fit(X)\n",
    "X_train_scaled=scalar.transform(X_train)\n",
    "X_test_scaled=scalar.transform(X_test)\n",
    "\n",
    "#Random Forest Regression\n",
    "r_model=RandomForestRegressor(random_state=1,n_estimators=1000)\n",
    "r_model.fit(X_train_scaled,y_train)\n",
    "y_hat=r_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Root mean squared error\",np.sqrt(mean_squared_error(y_hat,y_test)))\n",
    "\n",
    "print(\"R squared\",r2_score(y_test,y_hat))\n",
    "ft=r_model.feature_importances_\n",
    "#print(ft)\n",
    "\n",
    "#Linear Regression\n",
    "r_model=LinearRegression()\n",
    "r_model.fit(X_train_scaled,y_train)\n",
    "y_hat=r_model.predict(X_test_scaled)\n",
    "print(\"Root mean squared error\",np.sqrt(mean_squared_error(y_hat,y_test)))\n",
    "print(\"R squared\",r2_score(y_test,y_hat))\n",
    "i=0\n",
    "#f=pd.DataFrame(zip([X.columns,x]),columns=)\n",
    "\n",
    "#for y in X.columns:\n",
    "#    print(y,x[i])\n",
    "#    i+=1\n",
    "x= list(np.round(r_model.coef_,2))\n",
    "y=pd.DataFrame(list(zip(X.columns,x)),columns=[\"Column names\",\"importance\"])\n",
    "#print(y)\n",
    "print(y.sort_values(by='importance'))\n",
    "\n",
    "#Extreme Gradient Boosting\n",
    "xgb = XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n",
    "                           colsample_bytree=1, max_depth=7)\n",
    "xgb.fit(X_train_scaled,y_train)\n",
    "y_hat = xgb.predict(X_test_scaled)\n",
    "print(\"Root mean squared error\",np.sqrt(mean_squared_error(y_hat,y_test)))\n",
    "print(\"R squared\",r2_score(y_test,y_hat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error 30468.649783507262\n",
      "R squared 0.8361458437871084\n",
      "Root mean squared error 8290750345644629.0\n",
      "R squared -1.2132176488766506e+22\n",
      "[12:03:40] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error 31759.89366632785\n",
      "R squared 0.8219634690333895\n",
      "5.02590696104666e+29\n",
      "Root mean squared error 596801222.1825435\n",
      "R squared -62865220.7407611\n"
     ]
    }
   ],
   "source": [
    "#Iteration 2\n",
    "#Onehot Encoding categorical variables\n",
    "Y=df['SalePrice']\n",
    "cat_columns=list((df.select_dtypes([object]).columns))\n",
    "X1 = pd.get_dummies(df, prefix_sep=\"_\",columns=cat_columns)\n",
    "X=X1.drop(['SalePrice'],axis=1)\n",
    "X=X.select_dtypes([np.number])\n",
    "for col in X.columns:\n",
    "    X[col].fillna(X[col].median(axis=0),inplace=True)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=.2)\n",
    "scalar=preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_scaled=scalar.transform(X_train)\n",
    "X_test_scaled=scalar.transform(X_test)\n",
    "\n",
    "#Random Forest Model\n",
    "r_model=RandomForestRegressor(random_state=1,n_estimators=1000)\n",
    "r_model.fit(X_train_scaled,y_train)\n",
    "y_hat=r_model.predict(X_test_scaled)\n",
    "print(\"Root mean squared error\",np.sqrt(mean_squared_error(y_hat,y_test)))\n",
    "print(\"R squared\",r2_score(y_test,y_hat))\n",
    "\n",
    "#Linear Model\n",
    "r_model=LinearRegression()\n",
    "r_model.fit(X_train_scaled,y_train)\n",
    "y_hat=r_model.predict(X_test_scaled)\n",
    "print(\"Root mean squared error\",np.sqrt(mean_squared_error(y_hat,y_test)))\n",
    "print(\"R squared\",r2_score(y_test,y_hat))\n",
    "\n",
    "#XGBoost\n",
    "xgb = XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,colsample_bytree=1, max_depth=7)\n",
    "xgb.fit(X_train_scaled,y_train)\n",
    "y_hat = xgb.predict(X_test_scaled)\n",
    "print(\"Root mean squared error\",np.sqrt(mean_squared_error(y_hat,y_test)))\n",
    "print(\"R squared\",r2_score(y_test,y_hat))\n",
    "\n",
    "#Neural Network\n",
    "\n",
    "regressor = MLPRegressor(hidden_layer_sizes = (100, 75, 50, 25), activation = 'relu', solver = 'sgd', learning_rate = 'adaptive', alpha = .00001, random_state = 1)\n",
    "regressor.fit(X_train_scaled, y_train)\n",
    "print(regressor.loss_)\n",
    "\n",
    "y_hat = regressor.predict(X_test_scaled)\n",
    "\n",
    "print(\"Root mean squared error\",np.sqrt(mean_squared_error(y_hat,y_test)))\n",
    "print(\"R squared\",r2_score(y_test,y_hat))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Root mean squared error 30256.897199665564\n",
      "Random Forest R squared 0.8548421568660485\n",
      "LR Root mean squared error 36567.54732507679\n",
      "LR R squared 0.7879767968633007\n",
      "[12:08:11] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:08:14] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:08:18] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:08:21] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:08:25] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "XGB Root mean squared error 28178.79685006751\n",
      "XGB R squared 0.8740968432393716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Root mean squared error 43292.953898172374\n",
      "NN R squared 0.7028154928828215\n",
      "KNN Root mean squared error 47285.03762940413\n",
      "KNN R squared 0.64548125351655\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Iteration 3\n",
    "#Onehot Encoding categorical variables. Checking CV\n",
    "Y=df['SalePrice']\n",
    "cat_columns=list((df.select_dtypes([object]).columns))\n",
    "X1 = pd.get_dummies(df, prefix_sep=\"_\",columns=cat_columns)\n",
    "X=X1.drop(['SalePrice'],axis=1)\n",
    "X=X.select_dtypes([np.number])\n",
    "for col in X.columns:\n",
    "    X[col].fillna(X[col].median(axis=0),inplace=True)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=.2)\n",
    "scalar=preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_scaled=scalar.transform(X_train)\n",
    "X_test_scaled=scalar.transform(X_test)\n",
    "\n",
    "#Random Forest Model\n",
    "r_model=RandomForestRegressor(random_state=1,n_estimators=1000)\n",
    "y_hat = cross_val_predict(r_model, X, Y, cv=5)\n",
    "print(\"Random Forest Root mean squared error\",np.sqrt(mean_squared_error(y_hat,Y)))\n",
    "print(\"Random Forest R squared\",r2_score(Y,y_hat))\n",
    "\n",
    "r_model=LinearRegression()\n",
    "y_hat = cross_val_predict(r_model, X, Y, cv=5)\n",
    "print(\"LR Root mean squared error\",np.sqrt(mean_squared_error(y_hat,Y)))\n",
    "print(\"LR R squared\",r2_score(Y,y_hat))\n",
    "\n",
    "#XGBoost\n",
    "xgb = XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,colsample_bytree=1, max_depth=7)\n",
    "y_hat = cross_val_predict(xgb, X, Y, cv=5)\n",
    "print(\"XGB Root mean squared error\",np.sqrt(mean_squared_error(y_hat,Y)))\n",
    "print(\"XGB R squared\",r2_score(Y,y_hat))\n",
    "\n",
    "#Neural Network\n",
    "\n",
    "\n",
    "regressor = MLPRegressor(hidden_layer_sizes = (100,75,50, 25,5), activation = 'relu', solver = 'adam', alpha = .0001, random_state = 1)\n",
    "\n",
    "X2=pd.DataFrame(X).fillna(0)\n",
    "X2=X2.replace([np.inf, -np.inf], 0)\n",
    "y_hat = cross_val_predict(regressor, X2, Y, cv=5)\n",
    "print(\"NN Root mean squared error\",np.sqrt(mean_squared_error(y_hat,Y)))\n",
    "print(\"NN R squared\",r2_score(Y,y_hat))\n",
    "\n",
    "#KNN regression\n",
    "kmodel = neighbors.KNeighborsRegressor(n_neighbors = 10)\n",
    "y_hat = cross_val_predict(kmodel, X, Y, cv=5)\n",
    "print(\"KNN Root mean squared error\",np.sqrt(mean_squared_error(y_hat,Y)))\n",
    "print(\"KNN R squared\",r2_score(Y,y_hat))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  del sys.path[0]\n",
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error 29491.38077588801\n",
      "R squared 0.8613211251766625\n",
      "Root mean squared error 559157547561045.8\n",
      "R squared -4.985267642398797e+19\n",
      "[12:09:59] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error 27856.690032319653\n",
      "R squared 0.8762688299781602\n",
      "1.5104193745973567e+29\n",
      "Root mean squared error 438155292.5382347\n",
      "R squared -30610907.56925001\n"
     ]
    }
   ],
   "source": [
    "#Iteration 4\n",
    "Y=df['SalePrice']\n",
    "cat_columns=list((df.select_dtypes([object]).columns))\n",
    "X1 = pd.get_dummies(df, prefix_sep=\"_\",columns=cat_columns)\n",
    "X=X1.drop(['SalePrice'],axis=1)\n",
    "X=X.select_dtypes([np.number])\n",
    "for col in X.columns:\n",
    "    X[col].fillna(X[col].median(axis=0),inplace=True)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=.2)\n",
    "scalar=preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_scaled=scalar.transform(X_train)\n",
    "X_test_scaled=scalar.transform(X_test)\n",
    "\n",
    "\n",
    "#Random Forest Model\n",
    "r_model=RandomForestRegressor(random_state=1,n_estimators=1000)\n",
    "r_model.fit(X_train_scaled,y_train)\n",
    "y_hat=r_model.predict(X_test_scaled)\n",
    "print(\"Root mean squared error\",np.sqrt(mean_squared_error(y_hat,y_test)))\n",
    "print(\"R squared\",r2_score(y_test,y_hat))\n",
    "\n",
    "#Linear Model\n",
    "r_model=LinearRegression()\n",
    "r_model.fit(X_train_scaled,y_train)\n",
    "y_hat=r_model.predict(X_test_scaled)\n",
    "print(\"Root mean squared error\",np.sqrt(mean_squared_error(y_hat,y_test)))\n",
    "print(\"R squared\",r2_score(y_test,y_hat))\n",
    "\n",
    "#XGBoost\n",
    "xgb = XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,colsample_bytree=1, max_depth=7)\n",
    "xgb.fit(X_train_scaled,y_train)\n",
    "y_hat = xgb.predict(X_test_scaled)\n",
    "print(\"Root mean squared error\",np.sqrt(mean_squared_error(y_hat,y_test)))\n",
    "print(\"R squared\",r2_score(y_test,y_hat))\n",
    "\n",
    "#Neural Network\n",
    "\n",
    "regressor = MLPRegressor(hidden_layer_sizes = (100, 75, 50, 25), activation = 'relu', solver = 'sgd', learning_rate = 'adaptive', alpha = .00001, random_state = 1)\n",
    "regressor.fit(X_train_scaled, y_train)\n",
    "print(regressor.loss_)\n",
    "\n",
    "y_hat = regressor.predict(X_test_scaled)\n",
    "\n",
    "print(\"Root mean squared error\",np.sqrt(mean_squared_error(y_hat,y_test)))\n",
    "print(\"R squared\",r2_score(y_test,y_hat))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error 29104.562697639598\n",
      "R squared 0.8649351772897382\n",
      "[12:10:18] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error 26418.834972907905\n",
      "R squared 0.8887122350567032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1290d335278>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Principal Component Analysis\n",
    "xts=pd.DataFrame(X_train_scaled,index=X_train.index)\n",
    "pca = PCA(n_components=10)\n",
    "\n",
    "X_transformed = pd.DataFrame(pca.fit_transform(xts),index=xts.index,columns= ['pc1', 'pc2','pc3', 'pc4','pc5','pc6', 'pc7','pc8', 'pc9','pc10'])\n",
    "#a=list(pca.explained_variance_.round(2))\n",
    "y_train1=pd.DataFrame(y_train)\n",
    "a1=pd.concat([y_train,X_transformed],axis=1)\n",
    "#print(a1)\n",
    "xtts=pd.DataFrame(X_test_scaled,index=X_test.index)\n",
    "X_test_transformed = pd.DataFrame(pca.transform(xtts),index=xtts.index,columns= ['pc1', 'pc2','pc3', 'pc4','pc5','pc6', 'pc7','pc8', 'pc9','pc10'])\n",
    "\n",
    "r_model=RandomForestRegressor(random_state=1,n_estimators=1000)\n",
    "r_model.fit(X_transformed,y_train)\n",
    "y_hat=r_model.predict(X_test_transformed)\n",
    "print(\"Root mean squared error\",np.sqrt(mean_squared_error(y_hat,y_test)))\n",
    "print(\"R squared\",r2_score(y_test,y_hat))\n",
    "#print(list(zip(y_test,y_hat)))\n",
    "\n",
    "\n",
    "xgb = XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,colsample_bytree=1, max_depth=7)\n",
    "xgb.fit(X_transformed,y_train)\n",
    "y_hat = xgb.predict(X_test_transformed)\n",
    "print(\"Root mean squared error\",np.sqrt(mean_squared_error(y_hat,y_test)))\n",
    "print(\"R squared\",r2_score(y_test,y_hat))\n",
    "plt.scatter(y_test,y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual min & max: 34900     755000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Root mean squared error 30256.897199665564\n",
      "Random Forest R squared 0.8548421568660485\n",
      "LR Root mean squared error 35230.78495962207\n",
      "LR R squared 0.8031948919685583\n",
      "LR predicted min & max: 34900     755000\n",
      "[12:14:41] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:14:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:14:48] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:14:52] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:14:56] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "XGB Root mean squared error 28178.79685006751\n",
      "XGB R squared 0.8740968432393716\n",
      "XGB predicted min & max: 51797.62     602778.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Root mean squared error 41219.09832437177\n",
      "NN R squared 0.7306055144101318\n",
      "NN predicted min & max: 34900     755000\n",
      "KNN Root mean squared error 47285.03762940413\n",
      "KNN R squared 0.64548125351655\n",
      "KNN predicted min & max: 82530.0     424927.5\n",
      "Root mean squared error 30506.67286875476\n",
      "R squared 0.8524356608872004\n",
      "56232.86472410909 513428.30714999995\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('C:/Users/Nandhini Giridharan/Downloads/train.csv')\n",
    "\n",
    "\n",
    "#Iteration 4. Capping predicted outliers\n",
    "print(\"Actual min & max:\", Y.min(),\"   \",Y.max())\n",
    "m1=Y.min()\n",
    "m2=Y.max()\n",
    "\n",
    "#Onehot Encoding categorical variables\n",
    "Y=df['SalePrice']\n",
    "cat_columns=list((df.select_dtypes([object]).columns))\n",
    "X1 = pd.get_dummies(df, prefix_sep=\"_\",columns=cat_columns)\n",
    "X=X1.drop(['SalePrice'],axis=1)\n",
    "X=X.select_dtypes([np.number])\n",
    "for col in X.columns:\n",
    "    X[col].fillna(X[col].median(axis=0),inplace=True)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=.2)\n",
    "scalar=preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_scaled=scalar.transform(X_train)\n",
    "X_test_scaled=scalar.transform(X_test)\n",
    "\n",
    "#Random Forest Model\n",
    "r_model=RandomForestRegressor(random_state=1,n_estimators=1000)\n",
    "y_hat1 = cross_val_predict(r_model, X, Y, cv=5)\n",
    "y_hat= [m1 if x<m1 else m2 if x>m2 else x for x in y_hat1]\n",
    "print(\"Random Forest Root mean squared error\",np.sqrt(mean_squared_error(y_hat1,Y)))\n",
    "print(\"Random Forest R squared\",r2_score(Y,y_hat1))\n",
    "#print(\"RF predicted min & max:\", y_hat.min(),\"   \",y_hat.max())\n",
    "\n",
    "#Linear Regression\n",
    "r_model=LinearRegression()\n",
    "y_hat2 = cross_val_predict(r_model, X, Y, cv=5)\n",
    "y_hat2= [m1 if x<m1 else m2 if x>m2 else x for x in y_hat2]\n",
    "print(\"LR Root mean squared error\",np.sqrt(mean_squared_error(y_hat2,Y)))\n",
    "print(\"LR R squared\",r2_score(Y,y_hat2))\n",
    "print(\"LR predicted min & max:\", min(y_hat2),\"   \",max(y_hat2))\n",
    "\n",
    "#XGBoost\n",
    "xgb = XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,colsample_bytree=1, max_depth=7)\n",
    "y_hat3 = cross_val_predict(xgb, X, Y, cv=5)\n",
    "y_hat3= [m1 if x<m1 else m2 if x>m2 else x for x in y_hat3]\n",
    "print(\"XGB Root mean squared error\",np.sqrt(mean_squared_error(y_hat3,Y)))\n",
    "print(\"XGB R squared\",r2_score(Y,y_hat3))\n",
    "print(\"XGB predicted min & max:\", min(y_hat3),\"   \",max(y_hat3))\n",
    "\n",
    "\n",
    "#Neural Network\n",
    "regressor = MLPRegressor(hidden_layer_sizes = (100,75,50, 25,5), activation = 'relu', solver = 'adam', alpha = .0001, random_state = 1)\n",
    "\n",
    "X2=pd.DataFrame(X).fillna(0)\n",
    "X2=X2.replace([np.inf, -np.inf], 0)\n",
    "y_hat4 = cross_val_predict(regressor, X2, Y, cv=5)\n",
    "y_hat4= [m1 if x<m1 else m2 if x>m2 else x for x in y_hat4]\n",
    "print(\"NN Root mean squared error\",np.sqrt(mean_squared_error(y_hat4,Y)))\n",
    "print(\"NN R squared\",r2_score(Y,y_hat4))\n",
    "print(\"NN predicted min & max:\", min(y_hat4),\"   \",max(y_hat4))\n",
    "\n",
    "\n",
    "#KNN regression\n",
    "kmodel = neighbors.KNeighborsRegressor(n_neighbors = 10)\n",
    "y_hat5 = cross_val_predict(kmodel, X, Y, cv=5)\n",
    "y_hat5= [m1 if x<m1 else m2 if x>m2 else x for x in y_hat5]\n",
    "print(\"KNN Root mean squared error\",np.sqrt(mean_squared_error(y_hat5,Y)))\n",
    "print(\"KNN R squared\",r2_score(Y,y_hat5))\n",
    "print(\"KNN predicted min & max:\", min(y_hat5),\"   \",max(y_hat5))\n",
    "\n",
    "final_y_hat=(y_hat1+y_hat2+y_hat3+y_hat4+y_hat5)/5\n",
    "\n",
    "\n",
    "print(\"Root mean squared error\",np.sqrt(mean_squared_error(final_y_hat,Y)))\n",
    "print(\"R squared\",r2_score(Y,final_y_hat))\n",
    "\n",
    "print(min(final_y_hat),max(final_y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Root mean squared error 27128.443974963346\n",
      "LR R squared 0.8833078891827219\n",
      "LR predicted min & max: 46604.36199500665     598809.2584931433\n",
      "[('RF', 0.0), ('LR', 0.24), ('XGB', 0.78), ('NN', -0.06), ('KNN', 0.1)]\n"
     ]
    }
   ],
   "source": [
    "#Modeling of models:\n",
    "\n",
    "f_data=pd.DataFrame(zip(y_hat1,y_hat2,y_hat3,y_hat4,y_hat5),columns=[\"RF\",\"LR\",\"XGB\",\"NN\",\"KNN\"])\n",
    "#print(f_data.head(10))\n",
    "#print(Y.head(10))\n",
    "f_model=LinearRegression()\n",
    "f_model.fit(f_data, Y)\n",
    "f_hat=f_model.predict(f_data)\n",
    "f_hat= [m1 if x<m1 else m2 if x>m2 else x for x in f_hat]\n",
    "print(\"LR Root mean squared error\",np.sqrt(mean_squared_error(f_hat,Y)))\n",
    "print(\"LR R squared\",r2_score(Y,f_hat))\n",
    "print(\"LR predicted min & max:\", min(f_hat),\"   \",max(f_hat))\n",
    "x= list(np.round(f_model.coef_,2))\n",
    "col1= list(f_data.columns)\n",
    "print(list(zip(col1,x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562393.048\n"
     ]
    }
   ],
   "source": [
    "print(max(y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First iteration:\\nOnly Continuous variables, everything scaled\\nLinear Regression:0.84\\nRandomForest:.88\\nXGB:.89\")\n",
    "print(\"\\n\\nSecond iteration:\\nCatergorical variables one hot encoding, everything scaled\\nLinear Regression:0.84\\nRandomForest:.88\\nXGB:.90\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preferred model\n",
    "xgb = XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,colsample_bytree=1, max_depth=7)\n",
    "scalar=preprocessing.StandardScaler().fit(X)\n",
    "X_t_scaled=scalar.transform(X)\n",
    "xgb.fit(X_t_scaled,Y)\n",
    "\n",
    "#Reading test set\n",
    "val_df=pd.read_csv(\"C:/Users/Nandhini Giridharan/Downloads/test.csv\")\n",
    "\n",
    "#Categorical variable treatment - One hot encoding\n",
    "X1 = pd.get_dummies(val_df, prefix_sep=\"_\",columns=cat_columns)\n",
    "X=X1.select_dtypes([np.number])\n",
    "for col in X.columns:\n",
    "    X[col].fillna(X[col].median(axis=0),inplace=True)\n",
    "\n",
    "#Replacing columns with 0, if found missing in the test set    \n",
    "extra_cols=list(set(list(X_train.columns))-set(list(X.columns)))\n",
    "for d in extra_cols:\n",
    "    X[d]=0\n",
    "    \n",
    "#Scaling test set\n",
    "X_scaled=scalar.transform(X)\n",
    "y_hat = xgb.predict(X_scaled)\n",
    "y_hat= [m1 if x<m1 else m2 if x>m2 else x for x in y_hat]\n",
    "result=pd.DataFrame(X['Id']).join(pd.DataFrame(y_hat,columns=[\"SalePrice\"]))\n",
    "result.to_csv('C:/Users/Nandhini Giridharan/Downloads/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  del sys.path[0]\n",
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\Nandhini Giridharan\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:53:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "#Preferred model\n",
    "#Training set\n",
    "Y=df['SalePrice']\n",
    "cat_columns=list((df.select_dtypes([object]).columns))\n",
    "X1 = pd.get_dummies(df, prefix_sep=\"_\",columns=cat_columns)\n",
    "X=X1.drop(['SalePrice'],axis=1)\n",
    "X=X.select_dtypes([np.number])\n",
    "for col in X.columns:\n",
    "    X[col].fillna(X[col].median(axis=0),inplace=True)\n",
    "\n",
    "#Scaling\n",
    "scalar=preprocessing.StandardScaler().fit(X)\n",
    "xts=scalar.transform(X)\n",
    "\n",
    "xgb = XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,colsample_bytree=1, max_depth=7)\n",
    "\n",
    "\n",
    "\n",
    "m1=Y.min()\n",
    "m2=Y.max()\n",
    "\n",
    "#Reading test set\n",
    "val_df=pd.read_csv(\"C:/Users/Nandhini Giridharan/Downloads/test.csv\")\n",
    "\n",
    "#Categorical variable treatment - One hot encoding\n",
    "X1 = pd.get_dummies(val_df, prefix_sep=\"_\",columns=cat_columns)\n",
    "X=X1.select_dtypes([np.number])\n",
    "for col in X.columns:\n",
    "    X[col].fillna(X[col].median(axis=0),inplace=True)\n",
    "\n",
    "#Replacing columns with 0, if found missing in the test set    \n",
    "extra_cols=list(set(list(X_train.columns))-set(list(X.columns)))\n",
    "for d in extra_cols:\n",
    "    X[d]=0\n",
    "\n",
    "#Scaling test set\n",
    "scalar=preprocessing.StandardScaler().fit(X)\n",
    "#xts=scalar.transform(X)\n",
    "X_scaled=scalar.transform(X)\n",
    "\n",
    "#PCA transformation\n",
    "pca = PCA(n_components=10)\n",
    "X_transformed = pd.DataFrame(pca.fit_transform(xts),columns= ['pc1', 'pc2','pc3', 'pc4','pc5','pc6', 'pc7','pc8', 'pc9','pc10'])\n",
    "xgb.fit(X_transformed,Y)\n",
    "\n",
    "\n",
    "xtts=pd.DataFrame(X_scaled,index=X.index)\n",
    "X_test_transformed = pd.DataFrame(pca.fit_transform(xtts),columns= ['pc1', 'pc2','pc3', 'pc4','pc5','pc6', 'pc7','pc8', 'pc9','pc10'])\n",
    "\n",
    "\n",
    "#Apply Random Forest model\n",
    "r_model=RandomForestRegressor(random_state=1,n_estimators=1000)\n",
    "#r_model.fit(X_transformed,Y)\n",
    "#y_hat=r_model.predict(X_test_transformed)\n",
    "\n",
    "y_hat = xgb.predict(X_test_transformed)\n",
    "y_hat= [m1 if x<m1 else m2 if x>m2 else x for x in y_hat]\n",
    "result=pd.DataFrame(X['Id']).join(pd.DataFrame(y_hat,columns=[\"SalePrice\"]))\n",
    "\n",
    "\n",
    "\n",
    "y_hat= [m1 if x<m1 else m2 if x>m2 else x for x in y_hat]\n",
    "result=pd.DataFrame(X['Id']).join(pd.DataFrame(y_hat,columns=[\"SalePrice\"]))\n",
    "result.to_csv('C:/Users/Nandhini Giridharan/Downloads/submission.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           pc1       pc2       pc3       pc4       pc5       pc6       pc7  \\\n",
      "0    -3.358274 -3.194700 -1.500073  0.435279 -2.112624  0.289344 -0.141197   \n",
      "1    -0.920257 -4.647055  1.513579 -1.094477 -2.010772 -1.784916 -0.887350   \n",
      "2     2.229135  0.646669 -2.721852 -2.408736  0.789559  0.456259  0.871615   \n",
      "3     3.427930  1.122485 -1.820964 -2.337974  0.132440 -0.392892  0.806700   \n",
      "4     2.939601 -0.146697 -1.864800  3.263523  1.085521  0.329265  0.736576   \n",
      "5     1.306132  0.745996 -2.862583 -3.395960  0.995647 -0.143263 -0.590093   \n",
      "6     1.126125 -2.191001 -2.366864 -1.172265 -0.137979  0.838304  0.993250   \n",
      "7     1.863127  2.109847 -2.606920 -2.399717 -0.080699  0.112975 -0.072197   \n",
      "8     1.483093 -1.932364 -1.734014  0.478604 -0.388793  1.219557  0.834676   \n",
      "9    -2.576979 -5.000317 -1.702863  0.456955 -0.895863  1.321114 -0.516875   \n",
      "10    2.673597 -0.618703 -2.578330  4.010362  1.561627  1.333417  1.373144   \n",
      "11   -3.662626  0.024990 -5.000147  2.993305  3.127023 -4.634855 -2.429351   \n",
      "12   -3.549643  0.125668 -5.321649  2.316659  3.838712 -4.733645 -2.181399   \n",
      "13   -1.345792 -0.644575 -5.983571  1.065327  4.817359 -2.134351 -2.129069   \n",
      "14   -2.198675 -0.569076 -5.820940  3.826553  2.006796 -0.164672 -2.146425   \n",
      "15    7.860760  3.114989  4.491187 -0.471958 -1.798811 -2.579382 -2.832254   \n",
      "16    6.166037  2.259143  1.317871  0.304866 -4.394255  1.615165 -2.170242   \n",
      "17    6.632256 -0.084032  3.593457  0.408341 -2.337074 -1.560132 -1.442946   \n",
      "18    6.279469 -0.245834  3.476464  2.065544 -0.920057 -2.360058 -1.462635   \n",
      "19    9.653582 -2.394115  8.964256  1.802812  1.414411 -3.588060  1.471484   \n",
      "20    6.917897  1.205307  1.113388 -1.737788  0.412446 -0.112856  0.370702   \n",
      "21    5.258256  1.457389 -1.175728  2.799308 -0.423687  1.345917  0.170504   \n",
      "22    3.442940  1.643498 -1.346999 -1.593856 -2.903697  2.627492  0.280938   \n",
      "23    4.149938  1.831259 -3.186765  3.590354 -0.194835  2.403983  0.063477   \n",
      "24    3.876521  2.298514 -2.783205 -1.972016  0.644140  1.017624  1.631157   \n",
      "25    3.862745  3.888480 -2.641970 -2.997678 -0.029538  0.239737  0.903361   \n",
      "26    6.507074  1.693979  0.850091 -4.109996  0.316903 -1.194515  0.391415   \n",
      "27    4.940676  1.428521 -0.849092  0.170444 -2.798083  1.530572  0.216318   \n",
      "28    4.419155  3.325500 -0.688023  2.897748 -4.739430  2.046541 -1.329215   \n",
      "29    4.431875  1.167472 -0.112737  2.096882 -1.957075  1.055944  1.263636   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1429 -6.826668  2.324292  0.195376  2.249787 -2.474447 -0.195702  1.654241   \n",
      "1430 -3.101801  1.706624 -0.412281 -0.255011 -1.008457 -2.759515 -0.334531   \n",
      "1431 -8.198919  2.187998  3.793371  1.009828  1.318345  7.330235 -1.468512   \n",
      "1432 -7.185416  4.808523  4.039803  0.372269  5.484146  4.868919 -4.563954   \n",
      "1433 -8.838949  6.120415  4.557761  1.987176  0.837265  6.592116  1.069881   \n",
      "1434  7.073140 -0.628675  6.262961  9.709761  3.826325 -3.435765  2.250007   \n",
      "1435  5.634141 -1.312238  3.895398  8.202548  4.757464 -2.863168  4.041443   \n",
      "1436  1.302290 -4.100043  1.391662  0.405864  2.087579  2.220285  1.240663   \n",
      "1437 -1.576870 -1.491837  0.053819 -1.491357  2.060583  0.323915 -6.569928   \n",
      "1438  3.555619  1.045931  0.376772 -0.177178 -3.118349  1.260667 -1.015584   \n",
      "1439 -0.443953 -3.860772 -0.552335 -0.734867  0.508553  0.888152 -2.031839   \n",
      "1440  0.451905 -7.097714  5.190779 -0.001050  4.747214  4.068075  4.035321   \n",
      "1441  3.328217 -1.162723 -1.541623  1.817302 -1.085408  3.691450  1.823289   \n",
      "1442  7.414579  0.541456  4.085643  1.227318 -2.393098  1.753392 -1.091125   \n",
      "1443  8.143690 -0.482169  5.410862  2.337554 -1.767234 -0.569547 -2.103950   \n",
      "1444 -6.481502  0.163397  4.529725 -2.644076  0.015746  5.702280  0.104105   \n",
      "1445  1.695015 -0.943030 -0.182297  2.223727  4.010739 -0.105668 -2.013188   \n",
      "1446 -1.159093  2.724221 -4.427275  3.704094  4.940336 -2.727271 -0.614613   \n",
      "1447 -1.468981 -3.158434 -2.103857  0.317915 -0.977462  1.205655 -0.945567   \n",
      "1448 -1.369398 -2.605711  0.246106 -1.903463  1.789598  0.250248 -5.937502   \n",
      "1449 -3.835130  0.745915 -4.642194  8.634655  5.280084 -0.592776 -0.931706   \n",
      "1450 -4.102235  1.865294 -3.544327  5.378718  4.356009 -2.922966 -1.830329   \n",
      "1451 -0.497927 -4.883068  0.439309 -0.165006  1.644948  2.084888  0.693356   \n",
      "1452 -4.237073  1.292940 -4.366229  5.684607  4.833268 -4.465105 -3.101480   \n",
      "1453 -4.570555  2.789988 -4.303799  4.943901  4.881951 -3.275898 -2.037936   \n",
      "1454 -4.547079  3.002988 -4.386727  5.050363  4.520672 -3.474946 -1.709126   \n",
      "1455 -3.946398  1.386972 -3.841178  5.627889  4.421678 -4.034051 -2.801740   \n",
      "1456 -0.643436 -2.530642  0.429825 -1.758376 -1.787862  0.164697 -0.526614   \n",
      "1457 -2.263628 -1.144994 -2.174722  1.300018  1.501273  2.870041 -1.097075   \n",
      "1458  2.750857 -1.285425 -0.979953 -1.893879  3.365669 -0.484107  1.138842   \n",
      "\n",
      "           pc8       pc9      pc10  \n",
      "0    -0.426232  2.265127 -0.115096  \n",
      "1    -0.601632 -0.329325  1.135141  \n",
      "2     0.373083 -2.133022  1.288388  \n",
      "3    -0.313800 -1.343220  1.171748  \n",
      "4     0.514972 -0.663371  2.423733  \n",
      "5     1.276504 -2.506190  0.902329  \n",
      "6    -0.855132 -2.605841  0.297065  \n",
      "7     1.788170 -1.275851  1.450723  \n",
      "8    -0.545999 -2.291986  0.978279  \n",
      "9    -0.523579  0.305903  0.004539  \n",
      "10   -2.658645  3.804849  0.160936  \n",
      "11   -0.344171 -1.585738 -2.106258  \n",
      "12   -1.329825 -1.479925 -0.954411  \n",
      "13   -0.076731  3.080631  1.518087  \n",
      "14    0.942502  3.331017  2.007642  \n",
      "15    2.188676 -0.491874 -0.682391  \n",
      "16    2.042135  0.735333 -0.561206  \n",
      "17   -3.006014  0.595121  1.108723  \n",
      "18   -1.198071 -0.222145  1.033184  \n",
      "19   -1.614413 -0.549253  3.004471  \n",
      "20   -2.436679 -0.266004  0.282099  \n",
      "21   -1.573385  1.550606  1.483543  \n",
      "22    0.969321 -0.332838  1.627282  \n",
      "23   -1.929320  1.323692  1.306179  \n",
      "24    0.645932 -1.878916  0.853115  \n",
      "25    1.606974 -0.977056  1.216560  \n",
      "26   -1.766709  0.499744  1.112667  \n",
      "27   -1.324021  2.194647  0.817336  \n",
      "28    1.811038  3.203760 -1.666501  \n",
      "29   -2.149297  2.207282 -0.107289  \n",
      "...        ...       ...       ...  \n",
      "1429 -0.878941 -0.889074  0.049114  \n",
      "1430 -0.825120  0.193698 -0.644139  \n",
      "1431  0.659280 -1.333281 -2.957994  \n",
      "1432 -1.119490 -0.479066 -4.246076  \n",
      "1433 -2.483044 -6.365347 -7.304023  \n",
      "1434  4.365671 -2.409356  0.551041  \n",
      "1435  2.321325 -1.939488  2.366848  \n",
      "1436  2.143765 -1.607252  2.213467  \n",
      "1437  1.472592  2.293263  0.614557  \n",
      "1438  0.018646  0.748267  1.111344  \n",
      "1439 -0.262885 -1.472076 -0.688267  \n",
      "1440  8.704343  2.222493 -0.884194  \n",
      "1441 -0.489424 -0.633891  0.269912  \n",
      "1442  1.363955 -0.522187 -2.083229  \n",
      "1443  0.669921 -0.942840 -1.166627  \n",
      "1444 -1.283074 -1.596545 -3.625559  \n",
      "1445 -3.333544 -0.324853 -0.825701  \n",
      "1446  2.562652 -2.639396 -0.640867  \n",
      "1447  1.201411 -0.871916  0.408865  \n",
      "1448  1.497113  1.748585  0.401248  \n",
      "1449  1.662719 -4.117478 -1.105562  \n",
      "1450  2.348512 -2.292514 -0.166865  \n",
      "1451  0.708402  0.006819  1.094327  \n",
      "1452  4.025706 -2.808570 -1.631514  \n",
      "1453  2.966355 -2.832722 -0.598108  \n",
      "1454  3.031088 -2.837650 -0.500103  \n",
      "1455  3.914555 -2.434030 -1.248813  \n",
      "1456  0.670139 -1.308574 -0.243207  \n",
      "1457  0.878187 -3.164971  0.106854  \n",
      "1458  1.073806 -2.545829  0.969763  \n",
      "\n",
      "[1459 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_transformed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
